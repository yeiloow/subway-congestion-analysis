import json
import os

notebook_path = r"c:\Users\Administrator\Documents\subway-congestion-analysis\notebooks\추정매출_혼잡도_상관분석.ipynb"

# New cells to append
new_cells = [
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## 4. 업종별 매출과 혼잡도 상관분석\n",
            "\n",
            "전체 매출이 아닌, **업종(한식, 편의점, 카페 등)**별로 어떤 시간대의 혼잡도와 연관이 높은지 분석합니다.",
        ],
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 1. 업종별로 매출 집계\n",
            "industry_revenue = df_revenue_latest.groupby(['admin_dong_code_short', 'service_type_name'])['month_sales_amt'].sum().reset_index()\n",
            "\n",
            "# 2. 주요 업종 선정 (매출 총액 기준 상위 20개)\n",
            "top_industries = industry_revenue.groupby('service_type_name')['month_sales_amt'].sum().sort_values(ascending=False).head(20).index.tolist()\n",
            'print(f"분석 대상 상위 20개 업종: {top_industries}")\n',
            "\n",
            "# 3. 피벗 테이블 생성 (행: 행정동, 열: 업종별 매출)\n",
            "industry_pivot = industry_revenue[industry_revenue['service_type_name'].isin(top_industries)].pivot(\n",
            "    index='admin_dong_code_short', \n",
            "    columns='service_type_name', \n",
            "    values='month_sales_amt'\n",
            ").fillna(0)\n",
            "\n",
            "# 4. 역 정보와 병합\n",
            "# 하나의 역이 여러 행정동에 걸쳐있을 수 있으므로, 역 단위로 평균/합계를 내거나 해야 하는데,\n",
            "# 여기서는 '역-행정동' 매핑 테이블(station_dong)을 기준으로 병합합니다.\n",
            "station_industry_sales = station_dong.merge(industry_pivot, on='admin_dong_code_short', how='left')\n",
            "\n",
            "# 5. 혼잡도 데이터와 병합\n",
            "# station_id를 기준으로 혼잡도 데이터 병합\n",
            "analysis_df = station_industry_sales.merge(congestion_by_time, on='station_id', how='inner')\n",
            "\n",
            "# 결측치 처리 (매출 데이터가 없는 역 제외)\n",
            "analysis_df = analysis_df.dropna(subset=top_industries)\n",
            "\n",
            'print(f"최종 분석 대상 데이터: {len(analysis_df)}개 역")\n',
            "display(analysis_df.head())",
        ],
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 상관관계 분석\n",
            "# X축: 혼잡도 시간대 (cong_00_06 ~ cong_21_24, cong_avg)\n",
            "# Y축: 업종별 매출\n",
            "\n",
            "cong_cols = [c for c in analysis_df.columns if c.startswith('cong_')]\n",
            "industry_cols = top_industries\n",
            "\n",
            "# 상관계수 계산\n",
            "corr_matrix = pd.DataFrame(index=industry_cols, columns=cong_cols)\n",
            "\n",
            "for ind in industry_cols:\n",
            "    for cong in cong_cols:\n",
            "        # 피어슨 상관계수\n",
            "        corr, _ = stats.pearsonr(analysis_df[ind], analysis_df[cong])\n",
            "        corr_matrix.loc[ind, cong] = corr\n",
            "\n",
            "corr_matrix = corr_matrix.astype(float)\n",
            "\n",
            "# 시각화 (히트맵)\n",
            "fig = go.Figure(data=go.Heatmap(\n",
            "    z=corr_matrix.values,\n",
            "    x=corr_matrix.columns,\n",
            "    y=corr_matrix.index,\n",
            "    colorscale='RdBu_r', # 빨간색이 양의 상관관계\n",
            "    zmin=-1, zmax=1,\n",
            "    text=np.round(corr_matrix.values, 2),\n",
            '    texttemplate="%{text}",\n',
            "    textfont=dict(size=10)\n",
            "))\n",
            "\n",
            "fig.update_layout(\n",
            "    title='업종별 매출과 시간대별 지하철 혼잡도 상관관계',\n",
            "    xaxis_title='혼잡도 시간대',\n",
            "    yaxis_title='업종',\n",
            "    width=1000,\n",
            "    height=800,\n",
            "    xaxis=dict(tickangle=45)\n",
            ")\n",
            "\n",
            "fig.show()",
        ],
    },
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# 주요 상관관계 상세 시각화 (산점도)\n",
            "# 상관계수가 가장 높은 조합 Top 3 찾기\n",
            "\n",
            "stacked_corr = corr_matrix.stack().reset_index()\n",
            "stacked_corr.columns = ['Business', 'Time', 'Correlation']\n",
            "# 자기 자신과의 상관관계 등 제외 (여기서는 서로 다른 변수라 괜찮음)\n",
            "top_corr = stacked_corr.reindex(stacked_corr.Correlation.abs().sort_values(ascending=False).index).head(3)\n",
            "\n",
            'print("가장 강한 상관관계를 보인 조합 Top 3:")\n',
            "print(top_corr)\n",
            "\n",
            "# 시각화\n",
            "for _, row in top_corr.iterrows():\n",
            "    ind = row['Business']\n",
            "    cong = row['Time']\n",
            "    corr_val = row['Correlation']\n",
            "    \n",
            "    fig = go.Figure()\n",
            "    \n",
            "    fig.add_trace(go.Scatter(\n",
            "        x=analysis_df[cong],\n",
            "        y=analysis_df[ind],\n",
            "        mode='markers',\n",
            "        text=analysis_df['station_name_kr'], # 호버 시 역 이름 표시\n",
            "        marker=dict(size=8, opacity=0.6)\n",
            "    ))\n",
            "    \n",
            "    # 추세선 (Using numpy polyfit)\n",
            "    z = np.polyfit(analysis_df[cong], analysis_df[ind], 1)\n",
            "    p = np.poly1d(z)\n",
            "    \n",
            "    fig.add_trace(go.Scatter(\n",
            "        x=analysis_df[cong],\n",
            "        y=p(analysis_df[cong]),\n",
            "        mode='lines',\n",
            "        name='Trendline',\n",
            "        line=dict(color='red', dash='dash')\n",
            "    ))\n",
            "    \n",
            "    fig.update_layout(\n",
            "        title=f'{ind} 매출 vs {cong} (Corr: {corr_val:.2f})',\n",
            "        xaxis_title=f'{cong} (혼잡도)',\n",
            "        yaxis_title=f'{ind} 월 매출',\n",
            "        hovermode='closest'\n",
            "    )\n",
            "    \n",
            "    fig.show()",
        ],
    },
]

with open(notebook_path, "r", encoding="utf-8") as f:
    nb = json.load(f)

nb["cells"].extend(new_cells)

with open(notebook_path, "w", encoding="utf-8") as f:
    json.dump(nb, f, indent=1, ensure_ascii=False)

print("Cells appended successfully.")
